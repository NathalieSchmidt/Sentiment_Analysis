{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Dataset Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains IMDB movie reviews and is annotated wether it is a positive or a negative review. The task is to create a model, that can recognize if a review is good or bad. The dataset is taken from the Kaggle competetion that can be found [here](https://www.kaggle.com/columbine/imdb-dataset-sentiment-analysis-in-csv-format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "#plt.style.use( 'dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data by skipping the first line (header), then reading it line by line, then caching it, shuffling it, setting the batch size to 64 and also prefetching it to reduce step time during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b\"A major disappointment. This was one of the best UK crime drama / detective shows from the 90's which developed the fascinating title character played by Scotland's Robbie Coltrane. However this one-off has little to add and perhaps suffers from an inevitable let down due to raised expectations when a favored show returns after a long hiatus. Coltrane isn't really given much to do, much more attention is spent on the uninteresting killer, and in what he has to act in, he seems uninvolved, almost bored. The ex-soldier's story is written by the books and the attempt to update us on Coltrane's family life seems lightweight. Perhaps if the writers had a whole series in front of them instead of just this one two-hour show they would have written this with much more depth. As is, skip this and watch the old Cracker from the 90's which is far far superior.\">,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_line(line):\n",
    "    return tf.io.decode_csv(line, record_defaults=[str(), int()])\n",
    "\n",
    "train_data = tf.data.TextLineDataset('Train.csv') \\\n",
    "    .skip(1) \\\n",
    "    .map(decode_line) \\\n",
    "    .cache() \\\n",
    "    .shuffle(buffer_size=1024) \\\n",
    "    .batch(64) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# Skip header\n",
    "# Parse CSV file\n",
    "# Cache file to disk for better performance\n",
    "# Only training data is shuffled\n",
    "# Preload a single batch at all times in the background\n",
    "\n",
    "val_data = tf.data.TextLineDataset('Valid.csv') \\\n",
    "    .skip(1) \\\n",
    "    .map(decode_line) \\\n",
    "    .cache() \\\n",
    "    .batch(64) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_data = tf.data.TextLineDataset('Test.csv') \\\n",
    "    .skip(1) \\\n",
    "    .map(decode_line) \\\n",
    "    .cache() \\\n",
    "    .batch(64) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "x, y = next(iter(train_data))\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and cleaning the sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tokenizer Class will remove all dots, all numbers, transform every word into lower case and then split every sentence into tokens for each word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, name='Tokenizer'):\n",
    "        super(Tokenizer, self).__init__(self, name=name)\n",
    "    \n",
    "    def call(self, text):\n",
    "        # remove everything except words and spaces\n",
    "        text = tf.strings.regex_replace(text, r'[^\\w\\s]', '')\n",
    "        # remove digits\n",
    "        text = tf.strings.regex_replace(text, r'\\d', '')\n",
    "        # all letters to lower case\n",
    "        text = tf.strings.lower(text)\n",
    "        # tokenize sentencese to single word tokens\n",
    "        return tf.strings.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(190,), dtype=string, numpy=\n",
       " array([b'this', b'film', b'concerns', b'a', b'very', b'young', b'girl',\n",
       "        b'cassie', b'melissa', b'sagemiller', b'who', b'leaves', b'her',\n",
       "        b'family', b'and', b'heads', b'off', b'to', b'become', b'a',\n",
       "        b'college', b'freshman', b'one', b'night', b'cassie', b'and',\n",
       "        b'her', b'friends', b'decide', b'to', b'go', b'to', b'a', b'wild',\n",
       "        b'party', b'with', b'plenty', b'of', b'drinking', b'and',\n",
       "        b'dancing', b'and', b'cassie', b'is', b'riding', b'with', b'her',\n",
       "        b'boyfriend', b'who', b'she', b'likes', b'but', b'never', b'told',\n",
       "        b'him', b'she', b'loved', b'him', b'as', b'cassie', b'was',\n",
       "        b'driving', b'a', b'car', b'was', b'stopped', b'in', b'the',\n",
       "        b'middle', b'of', b'the', b'road', b'and', b'she', b'was',\n",
       "        b'unable', b'to', b'avoid', b'an', b'accident', b'and', b'as',\n",
       "        b'a', b'result', b'there', b'is', b'a', b'bloody', b'loss', b'of',\n",
       "        b'lives', b'along', b'with', b'her', b'boyfriend', b'cassie',\n",
       "        b'becomes', b'very', b'emotionally', b'upset', b'and', b'has',\n",
       "        b'nightmares', b'which', b'cause', b'her', b'to', b'have',\n",
       "        b'hallucinations', b'about', b'her', b'boyfriend', b'coming',\n",
       "        b'back', b'to', b'life', b'and', b'encounters', b'men', b'trying',\n",
       "        b'to', b'murder', b'her', b'and', b'she', b'is', b'struggling',\n",
       "        b'to', b'find', b'out', b'who', b'her', b'real', b'friends',\n",
       "        b'are', b'who', b'wants', b'her', b'dead', b'and', b'will', b'she',\n",
       "        b'survive', b'this', b'entire', b'horror', b'ordeal', b'cassie',\n",
       "        b'dreams', b'she', b'is', b'being', b'made', b'love', b'to', b'by',\n",
       "        b'her', b'boyfriend', b'after', b'he', b'died', b'and', b'finds',\n",
       "        b'another', b'guy', b'in', b'her', b'bed', b'and', b'is', b'told',\n",
       "        b'she', b'was', b'asking', b'him', b'to', b'make', b'love',\n",
       "        b'this', b'is', b'a', b'way', b'out', b'film', b'and', b'not',\n",
       "        b'very', b'good', b'at', b'all'], dtype=object)>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (tokenizer(x), y))\n",
    "val_data = val_data.map(lambda x, y: (tokenizer(x), y))\n",
    "test_data = test_data.map(lambda x, y: (tokenizer(x), y))\n",
    "\n",
    "x, y = next(iter(train_data))\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopwordFilter(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, sw, name='StopwordFilter'):\n",
    "        super(StopwordFilter, self).__init__(self, name=name)\n",
    "        \n",
    "        remove_words_keys = tf.constant(sw, dtype=tf.string)\n",
    "        remove_words_values = tf.fill([len(sw)], True)\n",
    "        \n",
    "        # Create a dict that maps a tf.string to True, if the string is in sw, else False\n",
    "        stopwords_init = tf.lookup.KeyValueTensorInitializer(\n",
    "                remove_words_keys, remove_words_values)\n",
    "        self.stopwords_table = tf.lookup.StaticHashTable(\n",
    "            stopwords_init, default_value=False)\n",
    "    \n",
    "    def call(self, words):\n",
    "        is_stopword = tf.ragged.map_flat_values(\n",
    "            self.stopwords_table.lookup, words)\n",
    "        is_stopword = tf.cast(is_stopword, tf.bool)\n",
    "        return tf.ragged.boolean_mask(words, ~is_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100,), dtype=string, numpy=\n",
       " array([b'expected', b'something', b'great', b'went', b'see', b'bomb',\n",
       "        b'basically', b'broadway', b'play', b'put', b'film', b'music',\n",
       "        b'plain', b'terrible', b'isnt', b'one', b'memorable', b'song',\n",
       "        b'movie', b'heard', b'hits', b'movie', b'wont', b'arent',\n",
       "        b'musical', b'numbers', b'go', b'long', b'got', b'go', b'restroom',\n",
       "        b'get', b'pop', b'corn', b'still', b'going', b'got', b'back',\n",
       "        b'good', b'songs', b'well', b'suck', b'pace', b'slow', b'terrible',\n",
       "        b'character', b'development', b'lead', b'praised', b'singing',\n",
       "        b'sounded', b'like', b'screamed', b'every', b'song', b'almost',\n",
       "        b'impossible', b'stand', b'movie', b'nothing', b'offer', b'anyone',\n",
       "        b'diehard', b'broadway', b'enthusiasts', b'without', b'doubt',\n",
       "        b'rated', b'movie', b'ive', b'seen', b'entire', b'life',\n",
       "        b'complete', b'waist', b'time', b'money', b'nothing', b'memorable',\n",
       "        b'movie', b'except', b'danny', b'glover', b'wasnt', b'screen',\n",
       "        b'enough', b'whose', b'character', b'wasnt', b'developed',\n",
       "        b'enough', b'rent', b'video', b'youll', b'agree', b'movie',\n",
       "        b'expensive', b'produced', b'polished', b'dog'], dtype=object)>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_filter = StopwordFilter(stopwords.words('english'))\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (stopword_filter(x), y))\n",
    "val_data = val_data.map(lambda x, y: (stopword_filter(x), y))\n",
    "test_data = test_data.map(lambda x, y: (stopword_filter(x), y))\n",
    "\n",
    "x, y = next(iter(train_data))\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each unique word will be transformed into an integer value. Therefore a vocabulary list of the data set needs to be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordIndexer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, vocab, name='WordIndexer'):\n",
    "        super(WordIndexer, self).__init__(self, name=name)\n",
    "        \n",
    "        vocab_keys = tf.constant(sorted(list(vocab)), dtype=tf.string)\n",
    "        vocab_values = tf.range(2, len(vocab_keys) + 2, dtype=tf.int64)\n",
    "        \n",
    "        # Create a dict that maps a tf.string to a unique index >= 2 for all of the strings in the vocab\n",
    "        # else return 1, 0 is reserved for padding\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(\n",
    "            vocab_keys, vocab_values)\n",
    "        self.vocab_table = tf.lookup.StaticHashTable(\n",
    "            vocab_init, default_value=1)\n",
    "\n",
    "    def call(self, words):\n",
    "        return tf.ragged.map_flat_values(self.vocab_table.lookup, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [01:50,  5.68it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for x, y in tqdm.tqdm(train_data):\n",
    "    vocab.update(word for text in x for word in text.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(88,), dtype=int64, numpy=\n",
       " array([148691,  83921, 141212,  48461,  79844,  27613, 148403, 112775,\n",
       "        135021,  83921,  56492,  32782,  16209,  83921,  68320,  29488,\n",
       "        130864,  19394,  45249,  35571, 138149,  39677,  23571,  50473,\n",
       "         64572, 135021,  79771, 152998,  78369, 118775,  11329,   6143,\n",
       "         16397,  26892, 140933,  83921, 148944,  87993, 148403,  48333,\n",
       "        119088,  89162,   9463,  16209,  84145,  66689,  74536,  22292,\n",
       "         47551,  48501,  16397,  98867,  48461, 141212,  44427,  77792,\n",
       "         70498,  85217,   9130,   1316,  66756,  83347,   7514,  64572,\n",
       "        100761, 131116, 104191,  44199,  80885,  48461, 124856, 153165,\n",
       "          1316,  44290, 120794,  24791,  23710,  81928,  70498,  79729,\n",
       "         56032,  26767, 153165,  48461, 120794,  79593,  79593, 138858])>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indexer = WordIndexer(vocab)\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (word_indexer(x), y))\n",
    "val_data = val_data.map(lambda x, y: (word_indexer(x), y))\n",
    "test_data = test_data.map(lambda x, y: (word_indexer(x), y))\n",
    "\n",
    "x, y = next(iter(train_data))\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longest sentence in the data defines the input size, sentences with less words need to be padded and thus filled with zeros to match the input size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fa91c40c8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fa91c40c8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "class Padder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, input_size, name='Padder'):\n",
    "        super(Padder, self).__init__(self, name=name)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "\n",
    "    def call(self, x):\n",
    "        # Pad the ragged tensors with 0 to build a full tensor\n",
    "        return x.to_tensor(default_value=0, shape=[None, self.input_size])\n",
    "\n",
    "input_size = max(train_data.map(lambda x, y: x.bounding_shape()[1]))\n",
    "padder = Padder(input_size)\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (padder(x), y))\n",
    "val_data = val_data.map(lambda x, y: (padder(x), y))\n",
    "test_data = test_data.map(lambda x, y: (padder(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 1440), dtype=int64, numpy=\n",
       " array([[149651,  36433,  47770, ...,      0,      0,      0],\n",
       "        [150557, 131489, 131298, ...,      0,      0,      0],\n",
       "        [ 44824,  89686, 111313, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [143957, 145295,  54005, ...,      0,      0,      0],\n",
       "        [153221,  35672, 140990, ...,      0,      0,      0],\n",
       "        [  6925,  90985, 104747, ...,      0,      0,      0]])>,\n",
       " <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
       " array([0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       dtype=int32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_data))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1440, 4)           622600    \n",
      "_________________________________________________________________\n",
      "separable_conv1d (SeparableC (None, 1440, 4)           48        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1440, 4)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 359, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 180, 8)            104       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 180, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 90, 16)            400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 90, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 45, 16)            784       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 45, 16)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 623,953\n",
      "Trainable params: 623,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input([input_size,]),\n",
    "    tf.keras.layers.Embedding(len(vocab) + 2, 4, input_length=input_size),\n",
    "    tf.keras.layers.SeparableConv1D(4, kernel_size=7, padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=5, strides=4),\n",
    "    tf.keras.layers.Conv1D(8, kernel_size=3, strides=2, padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv1D(16, kernel_size=3, strides=2, padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv1D(16, kernel_size=3, strides=2, padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Activation('sigmoid')])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.5440 - accuracy: 0.7074 - val_loss: 0.4184 - val_accuracy: 0.8118\n",
      "Epoch 2/8\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.3252 - accuracy: 0.8673 - val_loss: 0.3696 - val_accuracy: 0.8360\n",
      "Epoch 3/8\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.1749 - accuracy: 0.9369 - val_loss: 0.3466 - val_accuracy: 0.8810\n",
      "Epoch 4/8\n",
      "625/625 [==============================] - 37s 60ms/step - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.3998 - val_accuracy: 0.8752\n",
      "Epoch 5/8\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.0401 - accuracy: 0.9892 - val_loss: 0.4868 - val_accuracy: 0.8708\n",
      "Epoch 6/8\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0195 - accuracy: 0.9957 - val_loss: 0.5648 - val_accuracy: 0.8708\n",
      "Epoch 7/8\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.6493 - val_accuracy: 0.8656\n",
      "Epoch 8/8\n",
      "625/625 [==============================] - 35s 57ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.7222 - val_accuracy: 0.8612\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model_history = model.fit(train_data, validation_data=val_data, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the accuracy per epoch\n",
    "plt.plot(model_history.history['accuracy'], color=(0.2, 0.4, 0.6, 0.6))\n",
    "plt.plot(model_history.history['val_accuracy'], color=(0.2, 0.9, 0.8, 0.6))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.gcf().patch.set_alpha(0.0)\n",
    "plt.gca().patch.set_alpha(0.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 24ms/step - loss: 0.7184 - accuracy: 0.8534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7183563709259033, 0.8533999919891357]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with the preprocessing pipeline\n",
    "full_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([], dtype=tf.string),\n",
    "    tokenizer, stopword_filter, word_indexer, padder,\n",
    "    model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_positive_review = 'This is one of the finest science fiction ' \\\n",
    "    'films ever made. Everything is so carefully and expertly constructed ' \\\n",
    "    'to the point that repeated viewings are just as good as the first. ' \\\n",
    "    'Also, the atmosphere, along with the amazing sets, is real shocker ' \\\n",
    "    'and few movies have managed to create the same kind eerie feeling.'\n",
    "example_negative_review = 'I watch a lot of movies and I like to give them ' \\\n",
    "    'all a chance just in case there is something interesting or exciting to ' \\\n",
    "    'warrant a viewing Unfortunately this movie has none of these features it ' \\\n",
    "    'is pointless and offers nothing in the way of story line,acting or direction ' \\\n",
    "    'The plot is non-existent with the actors just going through the motions and ' \\\n",
    "    'the dialogue is sooo boring its embarrassing. I wish the previous reviewers ' \\\n",
    "    'had posted earlier as this would have saved me 95 mins of my time'\n",
    "test_sentence = 'So good. Very good. Best movie ever! So cool.'\n",
    "test2_sentence = 'I wish I could say: \"So good. Very good. Best movie ever!' \\\n",
    "    ' So cool.\" But this is not the case. It was actually hard to watch.'\n",
    "test3_sentence = 'Thanks for your attention!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 ]\n",
      " [0.   ]\n",
      " [0.979]\n",
      " [0.982]\n",
      " [0.977]]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(full_model(tf.constant([example_positive_review, \n",
    "                                  example_negative_review,\n",
    "                                  test_sentence, \n",
    "                                  test2_sentence, \n",
    "                                  test3_sentence])).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
